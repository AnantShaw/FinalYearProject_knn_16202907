{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation for the Advanced Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we use the Dynamic Time Warping Distance Metric to implement the Brute Force k-NN classifiers on case-bases created by different case-base editing algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from Conservative_RR.ipynb\n",
      "importing Jupyter notebook from Dynamic_tw.ipynb\n"
     ]
    }
   ],
   "source": [
    "#importing the necessary packages\n",
    "import import_ipynb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier  \n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "import dataset_loader as dl\n",
    "import time\n",
    "from scipy.spatial import distance\n",
    "import sklearn\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import timeit\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import time\n",
    "import Conservative_RR\n",
    "from Conservative_RR import crr2\n",
    "\n",
    "import Dynamic_tw\n",
    "from Dynamic_tw import dtw\n",
    "from Dynamic_tw import DTW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function takes the training and test sets and implements the Brute Force k-NN method on the original dataset, on the edited dataset after the implementation of the CNN algorithm and on the edited dataset after the implementation of the CRR algorithm. It simultaneously records the different model's speed and accuracy. The results are scaled w.r.t the Brute Force k-nn method, where the value 1 is the speed and accuracy of the Brute Force k-NN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_advance(X_train,y_train,X_test,y_test):\n",
    "    results_adv1=pd.DataFrame(columns=['Algorithms','Algorithm time','Brute force time','Brute force accuracy'])\n",
    "    results_adv1['Algorithms']=[\"None\",\"CNN\",\"CRR\"]\n",
    "    results_adv1_chart=pd.DataFrame()\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    import time\n",
    "    \n",
    "    #Brute Force on original dataset\n",
    "    classifier = KNeighborsClassifier(n_neighbors=5, algorithm=\"brute\", metric=DTW)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    tmp=0\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    start = time.perf_counter()\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    end = time.perf_counter()\n",
    "    tmp=accuracy_score(y_test,y_pred)\n",
    "    results_adv1.loc[0,\"Brute force accuracy\"]=tmp\n",
    "    results_adv1.loc[0,\"Algorithm time\"]=0\n",
    "    results_adv1.loc[0,\"Brute force time\"]=(end-start)\n",
    "    results_adv1.loc[0,\"Dataset Size\"]=X_train.shape[0]\n",
    "    \n",
    "    \n",
    "    #Brute Force on the case-base edited by thr CNN algorithm\n",
    "    tmp=0\n",
    "    from collections import Counter\n",
    "    from sklearn.datasets import fetch_mldata\n",
    "    from imblearn.under_sampling import CondensedNearestNeighbour\n",
    "    start = time.perf_counter()\n",
    "    cnn=CondensedNearestNeighbour(random_state=0)\n",
    "    X_cnn, y_cnn=cnn.fit_resample(X_train, y_train)\n",
    "    end = time.perf_counter()\n",
    "    tmp=(end-start)\n",
    "    results_adv1.loc[1,\"Algorithm time\"]=tmp\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    #Recording the representation of classes in the edited case base, and checking for an imbalanced dataset\n",
    "    test=pd.DataFrame()\n",
    "    test[\"Class\"]=y_cnn\n",
    "    p=test[test[\"Class\"] == '1'].shape[0]\n",
    "    q=test[test[\"Class\"] == '2'].shape[0]\n",
    "    classifier = KNeighborsClassifier(n_neighbors=5, algorithm=\"brute\", metric=DTW)\n",
    "    classifier.fit(X_cnn, y_cnn)\n",
    "    tmp=0\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    start = time.perf_counter()\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    end = time.perf_counter()\n",
    "    tmp=accuracy_score(y_test,y_pred)\n",
    "    #Recording the results\n",
    "    results_adv1.loc[1,\"Brute force accuracy\"]=tmp\n",
    "    results_adv1.loc[1,\"Brute force time\"]=(end-start)\n",
    "    results_adv1.loc[1,\"Dataset Size\"]=X_cnn.shape[0]\n",
    "    \n",
    "    #Brute Force k-NN on the edited case-base from the CRR algorithm\n",
    "    eset,results_adv1.loc[2,\"Algorithm time\"]=crr2(X_train,y_train) #Calling the crr2 function to form the edited case-base\n",
    "    X_crr=eset.iloc[:, :-1].values\n",
    "    y_crr=eset[\"Class\"].values\n",
    "    classifier = KNeighborsClassifier(n_neighbors=5, algorithm=\"brute\", metric=DTW)\n",
    "    classifier.fit(X_crr, y_crr)\n",
    "    tmp=0\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    start = time.perf_counter()\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    end = time.perf_counter()\n",
    "    tmp=accuracy_score(y_test,y_pred)\n",
    "    #Recording the results\n",
    "    results_adv1.loc[2,\"Brute force accuracy\"]=tmp\n",
    "    results_adv1.loc[2,\"Brute force time\"]=(end-start)\n",
    "    results_adv1.loc[2,\"Dataset Size\"]=X_crr.shape[0]\n",
    "    #Recording the representation of classes in the edited case base, and checking for an imbalanced dataset\n",
    "    test=pd.DataFrame()\n",
    "    test[\"Class\"]=y_crr\n",
    "    p2=test[test[\"Class\"] == '1'].shape[0]\n",
    "    q2=test[test[\"Class\"] == '2'].shape[0]\n",
    "    \n",
    "    #Scaling the results w.r.t Brute Force k-NN\n",
    "    results_adv1_chart['Time wrt BF']=[results_adv1['Brute force time'][0]/results_adv1['Brute force time'][0],results_adv1['Brute force time'][1]/results_adv1['Brute force time'][0],results_adv1['Brute force time'][2]/results_adv1['Brute force time'][0]]\n",
    "    results_adv1_chart['Accuracy wrt BF']=[results_adv1['Brute force accuracy'][0]/results_adv1['Brute force accuracy'][0],results_adv1['Brute force accuracy'][1]/results_adv1['Brute force accuracy'][0],results_adv1['Brute force accuracy'][2]/results_adv1['Brute force accuracy'][0]]\n",
    "    results_adv1_chart['Dataset size wrt BF']=[results_adv1['Dataset Size'][0]/results_adv1['Dataset Size'][0],results_adv1['Dataset Size'][1]/results_adv1['Dataset Size'][0],results_adv1['Dataset Size'][2]/results_adv1['Dataset Size'][0]]\n",
    "    return results_adv1,results_adv1_chart,X_cnn.shape,X_crr.shape,p,q,p2,q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
